{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affiche le chemin absolu vers le dossier courantg:\\我的云端硬盘\\M1\\Méthodologie de la Recherche en Informatique\\projet final\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "print(\"Affiche le chemin absolu vers le dossier courant\"+os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "                 #\"MNB\":MultinomialNB(),\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture du jeu de données Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # the return value will be an iterable object of type TextFileReader:\n",
    "chunks = pd.read_csv(\"spam.csv\",delimiter=\",\",chunksize=100000) ## 16*chunk\n",
    "df = pd.concat([chunk for chunk in chunks]) \n",
    "liste_tweets = df[\"text\"].values.tolist() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 5728 spamhams dans le jeu de données.\n",
      "Il y a 1878460 mots dans le jeu de données.\n",
      "Il y a 4360 spams dans le jeu de données.\n",
      "Il y a 1368 hams positifs dans le jeu de données.\n",
      "Il y a 91012 phrases dans l'ensemble du jeu de données.\n",
      "Il y a 13351968 caractères dans le jeu de données.\n"
     ]
    }
   ],
   "source": [
    "# compter NB des spam\n",
    "text = df[\"text\"]\n",
    "print(\"Il y a %s spamhams dans le jeu de données.\"%(len(text)))\n",
    "# compter les mots\n",
    "tokenizer = nltk.RegexpTokenizer(\"([A-Z]\\.[A-Z]?\\.?[0-9]?|[0-9]+[,.][0-9]+|[cdjls]'|qu'|[\\w'-]+|\\S)\")\n",
    "l = [len(tokenizer.tokenize(i)) for i in text]\n",
    "nb_mots = sum(l)\n",
    "print(\"Il y a %s mots dans le jeu de données.\"%(nb_mots))\n",
    "# compter les instances négatives et positives\n",
    "post_negatif= df[\"spam\"].value_counts()\n",
    "print(\"Il y a %s spams dans le jeu de données.\"%(post_negatif[0]))\n",
    "print(\"Il y a %s hams positifs dans le jeu de données.\"%(post_negatif[1]))\n",
    "\n",
    "\n",
    "nb_ph= 0\n",
    "for i in text:\n",
    "    longueur_text = len(sent_tokenize(i))\n",
    "    nb_ph += longueur_text\n",
    "print(\"Il y a %s phrases dans l'ensemble du jeu de données.\"%(nb_ph))\n",
    "\n",
    "nb_carac = 0\n",
    "for ii in text:\n",
    "    longueur_carac = len(i)\n",
    "    nb_carac += longueur_carac\n",
    "print(\"Il y a %s caractères dans le jeu de données.\"%(nb_carac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_classifier = [\n",
    "\n",
    "    [\"naive_bayes\",MultinomialNB()],\n",
    "    [\"Logistic Regression\", LogisticRegression()],\n",
    "    [\"Perceptron\", Perceptron(eta0=0.1, random_state=0,max_iter=10000)],\n",
    "    [\"Tree\",DecisionTreeClassifier()],\n",
    "    [\"linear_svc\", LinearSVC()]\n",
    "]\n",
    "\n",
    "liste_Vectorizer = [\n",
    "    [\"stop\",TfidfVectorizer(stop_words='english')],\n",
    "    [\"max_f:20000\",TfidfVectorizer(max_features = 20000)],\n",
    "    [\"word-ngram:1-2\",TfidfVectorizer(ngram_range = (1,2),analyzer =\"word\")],\n",
    "    [\"word-ngram:1-3\",TfidfVectorizer(ngram_range = (1,3),analyzer =\"word\")],\n",
    "    [\"char-ngram:1-8\",TfidfVectorizer(ngram_range=(1,8), analyzer=\"char\")],  # dico => liste  \n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 3 variants --> les param de tfidfVectorisation ; \n",
    "                   les paroles pretraitées ou pas ; \n",
    "                   les classifieurs \n",
    "    @param : list_string ==> pretraite ou pas | sortie : une liste triée (nb de vrai positif = bonne classification) avec les prama et les classifieurs choisis\"\"\"\n",
    "\n",
    "def resultat_param_algo(liste_string):\n",
    "    liste=[]\n",
    "    for nom_vec, V in liste_Vectorizer: \n",
    "        X = V.fit_transform(liste_string)\n",
    "        y = df['spam']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "        for nom, classifeur in liste_classifier: # on choisit les algorithmes\n",
    "            classifeur.fit(X_train, y_train)\n",
    "            y_pred = classifeur.predict(X_test)\n",
    "            precision = '%.4f' % (precision_score(y_test, y_pred,average='weighted'))\n",
    "            recall = '%.4f' % (recall_score(y_test, y_pred,average='weighted'))\n",
    "            accuracy = '%.4f' % (accuracy_score(y_test, y_pred))\n",
    "            f1_mesure = '%.4f' % (f1_score(y_test, y_pred,average='weighted'))\n",
    "            liste.append([precision,recall, accuracy,f1_mesure,nom_vec,nom])\n",
    "    return liste\n",
    "\n",
    "def affichier_resultat_param_algo(liste_string):      \n",
    "    # but : transformer la liste de resultatas en dataframe et l'afficher\n",
    "    liste_data = resultat_param_algo(liste_string)\n",
    "    df0 = DataFrame(sorted(liste_data,reverse=True))\n",
    "    df0.rename({0:'precision', 1:'racall',2:'accuracy',3:'f1-mesure',4:'@param',5:'@algorithme'}, axis='columns',inplace=True)\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste de spam : \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>racall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-mesure</th>\n",
       "      <th>@param</th>\n",
       "      <th>@algorithme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>max_f:20000</td>\n",
       "      <td>linear_svc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>max_f:20000</td>\n",
       "      <td>Perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>char-ngram:1-8</td>\n",
       "      <td>Perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9902</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>word-ngram:1-2</td>\n",
       "      <td>linear_svc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>word-ngram:1-2</td>\n",
       "      <td>Perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>stop</td>\n",
       "      <td>linear_svc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>char-ngram:1-8</td>\n",
       "      <td>linear_svc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>stop</td>\n",
       "      <td>Perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9810</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>word-ngram:1-3</td>\n",
       "      <td>Perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9796</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>max_f:20000</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>word-ngram:1-3</td>\n",
       "      <td>linear_svc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>stop</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>word-ngram:1-2</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>stop</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9552</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.9549</td>\n",
       "      <td>word-ngram:1-3</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>char-ngram:1-8</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>word-ngram:1-2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9481</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>max_f:20000</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>char-ngram:1-8</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9203</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>max_f:20000</td>\n",
       "      <td>naive_bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9184</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>word-ngram:1-3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9137</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>stop</td>\n",
       "      <td>naive_bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.8729</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>word-ngram:1-3</td>\n",
       "      <td>naive_bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>word-ngram:1-2</td>\n",
       "      <td>naive_bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.7970</td>\n",
       "      <td>0.7970</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>char-ngram:1-8</td>\n",
       "      <td>naive_bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  racall accuracy f1-mesure          @param          @algorithme\n",
       "0     0.9930  0.9930   0.9930    0.9930     max_f:20000           linear_svc\n",
       "1     0.9930  0.9930   0.9930    0.9930     max_f:20000           Perceptron\n",
       "2     0.9919  0.9919   0.9919    0.9919  char-ngram:1-8           Perceptron\n",
       "3     0.9902  0.9901   0.9901    0.9900  word-ngram:1-2           linear_svc\n",
       "4     0.9901  0.9901   0.9901    0.9901  word-ngram:1-2           Perceptron\n",
       "5     0.9895  0.9895   0.9895    0.9895            stop           linear_svc\n",
       "6     0.9884  0.9884   0.9884    0.9883  char-ngram:1-8           linear_svc\n",
       "7     0.9813  0.9814   0.9814    0.9813            stop           Perceptron\n",
       "8     0.9810  0.9808   0.9808    0.9806  word-ngram:1-3           Perceptron\n",
       "9     0.9796  0.9791   0.9791    0.9787     max_f:20000  Logistic Regression\n",
       "10    0.9790  0.9785   0.9785    0.9781  word-ngram:1-3           linear_svc\n",
       "11    0.9746  0.9738   0.9738    0.9733            stop  Logistic Regression\n",
       "12    0.9596  0.9593   0.9593    0.9594  word-ngram:1-2                 Tree\n",
       "13    0.9585  0.9587   0.9587    0.9586            stop                 Tree\n",
       "14    0.9552  0.9546   0.9546    0.9549  word-ngram:1-3                 Tree\n",
       "15    0.9528  0.9500   0.9500    0.9479  char-ngram:1-8  Logistic Regression\n",
       "16    0.9525  0.9494   0.9494    0.9472  word-ngram:1-2  Logistic Regression\n",
       "17    0.9481  0.9476   0.9476    0.9478     max_f:20000                 Tree\n",
       "18    0.9283  0.9279   0.9279    0.9280  char-ngram:1-8                 Tree\n",
       "19    0.9203  0.9110   0.9110    0.9031     max_f:20000          naive_bayes\n",
       "20    0.9184  0.9087   0.9087    0.9003  word-ngram:1-3  Logistic Regression\n",
       "21    0.9137  0.9034   0.9034    0.8940            stop          naive_bayes\n",
       "22    0.8729  0.8476   0.8476    0.8181  word-ngram:1-3          naive_bayes\n",
       "23    0.8721  0.8464   0.8464    0.8163  word-ngram:1-2          naive_bayes\n",
       "24    0.8396  0.7970   0.7970    0.7320  char-ngram:1-8          naive_bayes"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Liste de spam : \\n\")\n",
    "affichier_resultat_param_algo(liste_tweets) # 2 min 5.4 s"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f305f83ddee5f6083fe6bf1477dd3712b722d33e0c8e3d1f4b66e3f2a7ae2169"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
