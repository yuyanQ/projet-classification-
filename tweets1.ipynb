{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture du jeu de données Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # the return value will be an iterable object of type TextFileReader:\n",
    "chunks = pd.read_csv(\"french_tweets.csv\",delimiter=\",\",chunksize=100000) ## 16*chunk\n",
    "df = pd.concat([chunk for chunk in chunks]) \n",
    "liste_tweets = df[\"text\"].values.tolist()  #1.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>- Awww, c'est un bummer. Tu devrais avoir davi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Est contrarié qu'il ne puisse pas mettre à jou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>J'ai plongé plusieurs fois pour la balle. A ré...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tout mon corps a des démangeaisons et comme si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Non, il ne se comporte pas du tout. je suis en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  - Awww, c'est un bummer. Tu devrais avoir davi...\n",
       "1      0  Est contrarié qu'il ne puisse pas mettre à jou...\n",
       "2      0  J'ai plongé plusieurs fois pour la balle. A ré...\n",
       "3      0  Tout mon corps a des démangeaisons et comme si...\n",
       "4      0  Non, il ne se comporte pas du tout. je suis en..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 1526724 tweets dans le jeu de données.\n",
      "Il y a 25979719 mots dans le jeu de données.\n",
      "Il y a 771604 tweets négatifs dans le jeu de données.\n",
      "Il y a 755120 tweets positifs dans le jeu de données.\n",
      "Il y a 2572315 phrases dans l'ensemble du jeu de données.\n",
      "Il y a 119084472 caractères dans le jeu de données.\n"
     ]
    }
   ],
   "source": [
    "# compter NB des tweets\n",
    "text = df[\"text\"]\n",
    "print(\"Il y a %s tweets dans le jeu de données.\"%(len(text)))\n",
    "# compter les mots\n",
    "tokenizer = nltk.RegexpTokenizer(\"([A-Z]\\.[A-Z]?\\.?[0-9]?|[0-9]+[,.][0-9]+|[cdjls]'|qu'|[\\w'-]+|\\S)\")\n",
    "l = [len(tokenizer.tokenize(i)) for i in text]\n",
    "nb_mots = sum(l)\n",
    "print(\"Il y a %s mots dans le jeu de données.\"%(nb_mots))\n",
    "# compter les instances négatives et positives\n",
    "post_negatif_tweets = df[\"label\"].value_counts()\n",
    "print(\"Il y a %s tweets négatifs dans le jeu de données.\"%(post_negatif_tweets[0]))\n",
    "print(\"Il y a %s tweets positifs dans le jeu de données.\"%(post_negatif_tweets[1]))\n",
    "\n",
    "nb_ph= 0\n",
    "for i in text:\n",
    "    longueur_text = len(sent_tokenize(i))\n",
    "    nb_ph += longueur_text\n",
    "print(\"Il y a %s phrases dans l'ensemble du jeu de données.\"%(nb_ph))\n",
    "\n",
    "nb_carac = 0\n",
    "for ii in text:\n",
    "    longueur_carac = len(i)\n",
    "    nb_carac += longueur_carac\n",
    "print(\"Il y a %s caractères dans le jeu de données.\"%(nb_carac)) #42.1s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(liste_tweets)\n",
    "y = df['label']\n",
    "# séparer les datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) #14.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expériences stockées : 116\n"
     ]
    }
   ],
   "source": [
    "## chargement des expériences déjà faites\n",
    "import json\n",
    "import os\n",
    "chemin_expes = \"dic_expes_tweets.json\"\n",
    "if os.path.exists(chemin_expes):\n",
    "    f = open(chemin_expes)\n",
    "    dic_expes = json.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    dic_expes = {}\n",
    "print(\"Expériences stockées : %s\"%len(dic_expes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8038133872467894, \"['Logistic Regression', 1, 3, False, False, 40000]\"],\n",
       " [0.801715216432542, \"['linear_svc', 1, 3, False, False, 40000]\"],\n",
       " [0.7905038666602623, \"['Logistic Regression', 1, 3, False, False, 50000]\"],\n",
       " [0.7902091184189267, \"['Logistic Regression', 1, 4, False, False, 40000]\"],\n",
       " [0.790209118418926, \"['Logistic Regression', 1, 1, False, False, 40000]\"]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste = sorted([ [score,str]for str,score in dic_expes.items()],reverse = True)\n",
    "liste[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les paramètres max_depth, min_samples_split, max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth =  1   0.5765144601303879\n",
      "max_depth =  2   0.5901973284892733\n",
      "max_depth =  3   0.5902955779030519\n",
      "max_depth =  4   0.6016248269718657\n",
      "max_depth =  5   0.6022448899388234\n",
      "max_depth =  6   0.6098122781200739\n",
      "max_depth =  7   0.6165238047412984\n",
      "max_depth =  8   0.62195372234279\n",
      "max_depth =  9   0.6229951661288421\n",
      "max_depth =  10   0.6277635376775585\n",
      "max_depth =  11   0.6344444978144964\n",
      "max_depth =  12   0.6424856665021899\n",
      "max_depth =  13   0.647943967267662\n",
      "max_depth =  14   0.6521621420992189\n",
      "max_depth =  15   0.6565506159146584\n",
      "max_depth =  16   0.6602360605915052\n",
      "max_depth =  17   0.662766528826378\n",
      "max_depth =  18   0.6629106279665865\n",
      "max_depth =  19   0.6650109821011402\n"
     ]
    }
   ],
   "source": [
    "# max_depthint, default = None # plus de depth, plus de précision. En outre, plus de temps d'éxecution\n",
    "for i in range(1,20):\n",
    "    DTC = DecisionTreeClassifier(max_depth=i) \n",
    "    DTC = DTC.fit(X_train,y_train)\n",
    "    y_pred = DTC.predict(X_test)\n",
    "    nom_classes = [\"ham\", \"spam\"]\n",
    "    print(\"max_depth = \",i,\" \", accuracy_score(y_test, y_pred))\n",
    "    #report = classification_report(y_test,y_pred,target_names=nom_classes) \n",
    "    #print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split =  2 0.672351304970547\n",
      "--------------------\n",
      "min_samples_split =  3 0.6723185551659542\n",
      "--------------------\n",
      "min_samples_split =  4 0.6723425716893222\n",
      "--------------------\n",
      "min_samples_split =  5 0.6722989052831985\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#min_samples_split int or float, default=2. Nb de min_samples_split va nuancer la présicion de classification. \n",
    "for i in range(2,6):\n",
    "    DTC = DecisionTreeClassifier(max_depth=20,min_samples_split=i) \n",
    "    DTC = DTC.fit(X_train,y_train)\n",
    "    y_pred = DTC.predict(X_test)\n",
    "    nom_classes = [\"positif\", \"negatif\"]\n",
    "    print(\"min_samples_split = \",i,accuracy_score(y_test, y_pred))\n",
    "    #report = classification_report(y_test,y_pred,target_names=nom_classes)\n",
    "    #print(report)\n",
    "    print(\"-\"*20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_classifieurs= [[\"naive_bayes\",MultinomialNB()],\n",
    "    [\"Perceptron\", Perceptron(eta0=0.1, random_state=0)],\n",
    "    [\"Logistic Regression\", LogisticRegression()],\n",
    "    [\"Decision Tree\", DecisionTreeClassifier(max_depth=5)],\n",
    "    [\"linear_svc\", LinearSVC()]]\n",
    "    #[\"multi_couches\",MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(8, 2), random_state=1)]]#solver='sgd', max_iter=100000, random_state=0)]]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectoriser : Les paramètres lowercase, stop_words, max_features, analyzer = \"char\" ou \"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords : False, Minuscules : False\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.7077\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.7896\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.6023\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.7876\n",
      "Stopwords : False, Minuscules : True\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.7066\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.7891\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.6064\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.7866\n",
      "Stopwords : True, Minuscules : False\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.6866\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.7701\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.5636\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.7679\n",
      "Stopwords : True, Minuscules : True\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.6798\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.7638\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.5546\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.7609\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "\n",
    "min_N, max_N = 1, 4  #1,1  #1,3\n",
    "\n",
    "for enlever_stopwords in [False,True]:\n",
    "  liste_stopwords = None\n",
    "  if enlever_stopwords==True:\n",
    "    liste_stopwords = fr_stop\n",
    "    \n",
    "  for en_minuscules in [False, True]:\n",
    "    print(f\"Stopwords : {enlever_stopwords}, Minuscules : {en_minuscules}\")\n",
    "    for max_F in [20000]:\n",
    "        V = TfidfVectorizer(lowercase = en_minuscules, stop_words =  liste_stopwords, max_features = max_F )\n",
    "        X = V.fit_transform(liste_tweets)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "        for nom, algo in liste_classifieurs:\n",
    "            clf = algo.fit(X_train, y_train)\n",
    "            expe = str([nom, min_N, max_N, enlever_stopwords, en_minuscules, max_F])\n",
    "            if expe in dic_expes:\n",
    "                score = dic_expes[expe]\n",
    "                print(\"  Déjà vu :\",  expe, \"%.4f\"%score)       \n",
    "            else:\n",
    "                print(\"  Nouvelle expérience\")\n",
    "                score = clf.score(X_test, y_test)\n",
    "                print('  %s classifier : %.4f'%(nom, score)) \n",
    "                dic_expes[expe] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram_range : (1, 1)\n",
      "Logistic Regression classifier : 0.7896\n",
      "Ngram_range : (1, 2)\n",
      "Logistic Regression classifier : 0.8092\n",
      "Ngram_range : (1, 3)\n",
      "Logistic Regression classifier : 0.8107\n",
      "Ngram_range : (2, 2)\n",
      "Logistic Regression classifier : 0.7841\n",
      "Ngram_range : (2, 3)\n",
      "Logistic Regression classifier : 0.7818\n"
     ]
    }
   ],
   "source": [
    "liste_classifieurs= [\n",
    "    [\"Logistic Regression\", LogisticRegression()]]\n",
    "for min_N in range(1, 3):\n",
    "  for max_N in range(min_N, 4):\n",
    "    #analyzer: words, char, char_wb\n",
    "    V = TfidfVectorizer(ngram_range = (min_N, max_N), analyzer = \"word\")\n",
    "    X = V.fit_transform(liste_tweets)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "    print(f\"Ngram_range : ({min_N}, {max_N})\")\n",
    "    for nom, algo in liste_classifieurs:\n",
    "            clf = algo.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            dic_expes[expe] = score\n",
    "            print('%s classifier : %.4f'%(nom, score)) #13m11.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram_range : (4, 4)\n",
      "Logistic Regression classifier : 0.7979\n",
      "Ngram_range : (4, 5)\n",
      "Logistic Regression classifier : 0.8052\n",
      "Ngram_range : (4, 6)\n",
      "Logistic Regression classifier : 0.8095\n"
     ]
    }
   ],
   "source": [
    "liste_classifieurs= [\n",
    "    [\"Logistic Regression\", LogisticRegression()]]\n",
    "for min_N in range(4, 5):\n",
    "  for max_N in range(min_N, 7):\n",
    "    #analyzer: words, char, char_wb\n",
    "    V = TfidfVectorizer(ngram_range = (min_N, max_N), analyzer = \"char\")\n",
    "    X = V.fit_transform(liste_tweets)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "    print(f\"Ngram_range : ({min_N}, {max_N})\")\n",
    "    for nom, algo in liste_classifieurs:\n",
    "            clf = algo.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            dic_expes[expe] = score\n",
    "            print('%s classifier : %.4f'%(nom, score)) #13m11.5s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Expériences stockées dans dic_expes_tweets.json\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "### Stockez les résultats de classification dans des fichiers Json\n",
    "w = open(chemin_expes, \"w\")\n",
    "w.write(json.dumps(dic_expes))\n",
    "w.close()\n",
    "print(\"-\"*20)\n",
    "print(f\"Expériences stockées dans {chemin_expes}\")\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesure de l’efficacité de ces différents classifieurs: exactitude, précision, rappel, F-mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_Vectorizer = [\n",
    "    [\"param-vide\",TfidfVectorizer()],\n",
    "    [\"max_f:20000\",TfidfVectorizer(max_features = 30000)],\n",
    "    [\"word-ngram:1-2\",TfidfVectorizer(ngram_range = (1,2),analyzer =\"word\")],\n",
    "    [\"word-ngram:1-3\",TfidfVectorizer(ngram_range = (1,3),analyzer =\"word\")],\n",
    "    [\"char-ngram:1-8\",TfidfVectorizer(ngram_range=(1,8), analyzer=\"char\")]  # dico => liste   0.7s=>0.2s\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param-vide + Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.72      0.71      0.71    231214\n",
      "    negative       0.71      0.72      0.71    226804\n",
      "\n",
      "    accuracy                           0.71    458018\n",
      "   macro avg       0.71      0.71      0.71    458018\n",
      "weighted avg       0.71      0.71      0.71    458018\n",
      "\n",
      "param-vide + naive_bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.75      0.80      0.77    231214\n",
      "    negative       0.78      0.73      0.75    226804\n",
      "\n",
      "    accuracy                           0.76    458018\n",
      "   macro avg       0.76      0.76      0.76    458018\n",
      "weighted avg       0.76      0.76      0.76    458018\n",
      "\n",
      "param-vide + LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.79      0.78      0.78    231214\n",
      "    negative       0.78      0.79      0.78    226804\n",
      "\n",
      "    accuracy                           0.78    458018\n",
      "   macro avg       0.78      0.78      0.78    458018\n",
      "weighted avg       0.78      0.78      0.78    458018\n",
      "\n",
      "param-vide + Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.80      0.78      0.79    231214\n",
      "    negative       0.78      0.80      0.79    226804\n",
      "\n",
      "    accuracy                           0.79    458018\n",
      "   macro avg       0.79      0.79      0.79    458018\n",
      "weighted avg       0.79      0.79      0.79    458018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 variants --> les param de tfidfvectorisation ; les paroles pretraitées ou pas ; les 3 classifieurs \n",
    "# @param : list_string ==> pretraite ou pas | sortie : une liste triée (nb de vrai positif = bonne classification) avec les prama et les classifieurs choisis\n",
    "\n",
    "def resultat_param_algo(liste_string):\n",
    "    for nom_vec, V in liste_Vectorizer: \n",
    "        X = V.fit_transform(liste_string)\n",
    "        y = df['label']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "        for nom, classifeur in liste_classifieurs: # on choisit les algorithmes\n",
    "            classifeur.fit(X_train, y_train)\n",
    "            y_pred = classifeur.predict(X_test)\n",
    "            nom_classes = [\"positive\", \"negative\"]\n",
    "            report = classification_report(y_test,y_pred,target_names=nom_classes)\n",
    "            print(nom_vec,\"+\", nom)\n",
    "            print(report)\n",
    "resultat_param_algo(liste_tweets)   # 3 min 14.4s #20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords : False, Minuscules : False\n",
      "  Nouvelle expérience\n",
      "  naive_bayes classifier : 0.7887\n"
     ]
    }
   ],
   "source": [
    "min_N, max_N = 1, 4\n",
    "enlever_stopwords,en_minuscules = False,False\n",
    "\n",
    "print(f\"Stopwords : False, Minuscules : False\")\n",
    "#max_F = 40000\n",
    "V = TfidfVectorizer(lowercase = False, stop_words = None, max_features = None, ngram_range=(1,4), analyzer = \"word\")\n",
    "X = V.fit_transform(liste_tweets)\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "for nom, algo in liste_classifieurs:\n",
    "    clf = algo.fit(X_train, y_train)\n",
    "    expe = str([nom, min_N, max_N, enlever_stopwords, en_minuscules, None])\n",
    "    \n",
    "    if expe in dic_expes:\n",
    "        score = dic_expes[expe]\n",
    "            #expe.append()\n",
    "        print(\"  Déjà vu :\",  expe, \"%.4f\"%score)    \n",
    "    else:\n",
    "        print(\"  Nouvelle expérience\")\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print('  %s classifier : %.4f'%(nom, score))\n",
    "        dic_expes[expe] = score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['Logistic Regression', 2, 3, False, False, None]: 0.781,\n",
    "['Logistic Regression', 2, 2, False, False, None]: 0.784,\n",
    "['Logistic Regression', 1, 2, False, False, 0]: 0.809,\n",
    "['Logistic Regression', 1, 3, False, False, 0]: 0.81,\n",
    "['Logistic Regression', 1, 1, False, False, 0]: 0.789,"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f305f83ddee5f6083fe6bf1477dd3712b722d33e0c8e3d1f4b66e3f2a7ae2169"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
