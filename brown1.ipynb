{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture du jeu de données Brown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    " # the return value will be an iterable object of type TextFileReader:\n",
    "chunks = pd.read_csv(\"archive/brown.csv\",delimiter=\",\",chunksize=10000) ## 16*chunk\n",
    "df = pd.concat([chunk for chunk in chunks]) \n",
    "liste_brown = df[\"tokenized_text\"].values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>para_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tokenized_pos</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cd05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Furthermore/rb ,/, as/cs an/at encouragement/n...</td>\n",
       "      <td>Furthermore , as an encouragement to revisioni...</td>\n",
       "      <td>rb , cs at nn in nn nn , pps rb bez jj to vb c...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cd05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The/at Unitarian/jj clergy/nns were/bed an/at ...</td>\n",
       "      <td>The Unitarian clergy were an exclusive club of...</td>\n",
       "      <td>at jj nns bed at jj nn in vbn nns -- cs at nn ...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cd05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ezra/np Stiles/np Gannett/np ,/, an/at honorab...</td>\n",
       "      <td>Ezra Stiles Gannett , an honorable representat...</td>\n",
       "      <td>np np np , at jj nn in at nn , vbd ppl rb in a...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cd05</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Even/rb so/rb ,/, Gannett/np judiciously/rb ar...</td>\n",
       "      <td>Even so , Gannett judiciously argued , the Ass...</td>\n",
       "      <td>rb rb , np rb vbd , at nn-tl md rb vb cs np ``...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cd05</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>We/ppss today/nr are/ber not/* entitled/vbn to...</td>\n",
       "      <td>We today are not entitled to excoriate honest ...</td>\n",
       "      <td>ppss nr ber * vbn to vb jj nns wps vbd np to b...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  para_id  sent_id  \\\n",
       "0     cd05        0        0   \n",
       "1     cd05        0        1   \n",
       "2     cd05        0        2   \n",
       "3     cd05        0        3   \n",
       "4     cd05        0        4   \n",
       "\n",
       "                                            raw_text  \\\n",
       "0  Furthermore/rb ,/, as/cs an/at encouragement/n...   \n",
       "1  The/at Unitarian/jj clergy/nns were/bed an/at ...   \n",
       "2  Ezra/np Stiles/np Gannett/np ,/, an/at honorab...   \n",
       "3  Even/rb so/rb ,/, Gannett/np judiciously/rb ar...   \n",
       "4  We/ppss today/nr are/ber not/* entitled/vbn to...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  Furthermore , as an encouragement to revisioni...   \n",
       "1  The Unitarian clergy were an exclusive club of...   \n",
       "2  Ezra Stiles Gannett , an honorable representat...   \n",
       "3  Even so , Gannett judiciously argued , the Ass...   \n",
       "4  We today are not entitled to excoriate honest ...   \n",
       "\n",
       "                                       tokenized_pos     label  \n",
       "0  rb , cs at nn in nn nn , pps rb bez jj to vb c...  religion  \n",
       "1  at jj nns bed at jj nn in vbn nns -- cs at nn ...  religion  \n",
       "2  np np np , at jj nn in at nn , vbd ppl rb in a...  religion  \n",
       "3  rb rb , np rb vbd , at nn-tl md rb vb cs np ``...  religion  \n",
       "4  ppss nr ber * vbn to vb jj nns wps vbd np to b...  religion  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 57340 instances dans le jeu de données.\n",
      "Il y a 1175396 mots dans le jeu de données.\n",
      "Il y a 61435 phrases dans l'ensemble du jeu de données.\n",
      "Il y a 9518440 caractères dans le jeu de données.\n",
      "Il y a 15 classes dans l'ensemble du jeu de données.\n",
      "learned            7734\n",
      "belles_lettres     7209\n",
      "lore               4881\n",
      "adventure          4637\n",
      "news               4623\n",
      "romance            4431\n",
      "fiction            4249\n",
      "hobbies            4193\n",
      "mystery            3886\n",
      "government         3032\n",
      "editorial          2997\n",
      "reviews            1751\n",
      "religion           1716\n",
      "humor              1053\n",
      "science_fiction     948\n",
      "Name: label, dtype: int64\n",
      "{'belles_lettres', 'religion', 'mystery', 'reviews', 'government', 'adventure', 'humor', 'editorial', 'learned', 'lore', 'fiction', 'hobbies', 'romance', 'news', 'science_fiction'}\n"
     ]
    }
   ],
   "source": [
    "# compter NB des tweets\n",
    "text = df[\"tokenized_text\"]\n",
    "print(\"Il y a %s instances dans le jeu de données.\"%(len(text)))\n",
    "# compter les mots\n",
    "tokenizer = nltk.RegexpTokenizer(\"([A-Z]\\.[A-Z]?\\.?[0-9]?|[0-9]+[,.][0-9]+|[cdjls]'|qu'|[\\w'-]+|\\S)\")\n",
    "l = [len(tokenizer.tokenize(i)) for i in text]\n",
    "nb_mots = sum(l)\n",
    "print(\"Il y a %s mots dans le jeu de données.\"%(nb_mots))\n",
    "# compter les phrases et les caractères\n",
    "nb_ph= 0\n",
    "for i in text:\n",
    "    longueur_text = len(sent_tokenize(i))\n",
    "    nb_ph += longueur_text\n",
    "print(\"Il y a %s phrases dans l'ensemble du jeu de données.\"%(nb_ph))\n",
    "\n",
    "nb_carac = 0\n",
    "for ii in text:\n",
    "    longueur_carac = len(i)\n",
    "    nb_carac += longueur_carac\n",
    "print(\"Il y a %s caractères dans le jeu de données.\"%(nb_carac)) \n",
    "\n",
    "# compter les instances de 15 genres\n",
    "instances_genres = df[\"label\"].value_counts()\n",
    "print(\"Il y a %s classes dans l'ensemble du jeu de données.\"%(len(instances_genres)))\n",
    "print((instances_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(liste_brown)\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) #0.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expériences stockées : 129\n"
     ]
    }
   ],
   "source": [
    "## chargement des expériences déjà faites\n",
    "import json\n",
    "import os\n",
    "chemin_expes = \"dic_expes_brown.json\"\n",
    "if os.path.exists(chemin_expes):\n",
    "    f = open(chemin_expes)\n",
    "    dic_expes = json.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    dic_expes = {}\n",
    "print(\"Expériences stockées : %s\"%len(dic_expes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5277293337983955, \"['linear_svc', 1, 2, False, True, 30000]\"],\n",
       " [0.5277293337983955, \"['linear_svc', 1, 1, False, True, 30000]\"],\n",
       " [0.5256365538890827, \"['linear_svc', 1, 2, False, False, 30000]\"],\n",
       " [0.5256365538890827, \"['linear_svc', 1, 1, False, False, 30000]\"],\n",
       " [0.5245320311591676, \"['linear_svc', 1, 2, False, True, 20000]\"],\n",
       " [0.5245320311591676, \"['linear_svc', 1, 1, False, True, 20000]\"],\n",
       " [0.5232531101034763, \"['linear_svc', 1, 2, True, False, 40000]\"],\n",
       " [0.5215091268457156, \"['linear_svc', 1, 2, False, False, 20000]\"],\n",
       " [0.5215091268457156, \"['linear_svc', 1, 1, False, False, 20000]\"],\n",
       " [0.5202302057900244, \"['linear_svc', 1, 2, True, True, 40000]\"]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste = sorted([ [score,str]for str,score in dic_expes.items()],reverse = True)\n",
    "liste[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les paramètres max_depth, min_samples_split, max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth =  1\n",
      "0.14126264387861875\n",
      "--------------------\n",
      "max_depth =  2\n",
      "0.15341239390768516\n",
      "--------------------\n",
      "max_depth =  3\n",
      "0.15666782932217185\n",
      "--------------------\n",
      "max_depth =  4\n",
      "0.15934193698407162\n",
      "--------------------\n",
      "max_depth =  5\n",
      "0.16718986164399488\n",
      "--------------------\n",
      "max_depth =  6\n",
      "0.16992210208115335\n",
      "--------------------\n",
      "max_depth =  7\n",
      "0.18061853272875247\n",
      "--------------------\n",
      "max_depth =  8\n",
      "0.18021160330194164\n",
      "--------------------\n",
      "max_depth =  9\n",
      "0.1879432624113475\n",
      "--------------------\n",
      "max_depth =  10\n",
      "0.18980351121962563\n",
      "--------------------\n",
      "max_depth =  11\n",
      "0.19143122892686898\n",
      "--------------------\n",
      "max_depth =  12\n",
      "0.19480292989187303\n",
      "--------------------\n",
      "max_depth =  13\n",
      "0.1949773282176491\n",
      "--------------------\n",
      "max_depth =  14\n",
      "0.19567492152075341\n",
      "--------------------\n",
      "max_depth =  15\n",
      "0.1994535519125683\n",
      "--------------------\n",
      "max_depth =  16\n",
      "0.19863969305894663\n",
      "--------------------\n",
      "max_depth =  17\n",
      "0.1975351703290315\n",
      "--------------------\n",
      "max_depth =  18\n",
      "0.19643064759911638\n",
      "--------------------\n",
      "max_depth =  19\n",
      "0.19782583420532496\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#max_depthint, default=None\n",
    "for i in range(1,20):\n",
    "    DTC = DecisionTreeClassifier(max_depth=i)   \n",
    "    DTC = DTC.fit(X_train,y_train)\n",
    "    #y_pred = DTC.predict(X_test)\n",
    "    print(\"max_depth = \",i )\n",
    "    #report = classification_report(y_test,y_pred)\n",
    "    #print(report)\n",
    "    print(DTC.score(X_test,y_test))\n",
    "    print(\"-\"*20)    #max_depth =  15 0.1994535519125683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split =  2\n",
      "0.19991861411463782\n",
      "--------------------\n",
      "min_samples_split =  3\n",
      "0.2000348796651552\n",
      "--------------------\n",
      "min_samples_split =  4\n",
      "0.19997674688989653\n",
      "--------------------\n",
      "min_samples_split =  5\n",
      "0.19986048133937914\n",
      "--------------------\n",
      "min_samples_split =  6\n",
      "0.19991861411463782\n",
      "--------------------\n",
      "min_samples_split =  7\n",
      "0.2000348796651552\n",
      "--------------------\n",
      "min_samples_split =  8\n",
      "0.19951168468782698\n",
      "--------------------\n",
      "min_samples_split =  9\n",
      "0.19927915358679224\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#min_samples_split int or float, default=2   没有影响\n",
    "for i in range(2,10):\n",
    "    DTC = DecisionTreeClassifier(max_depth=15,min_samples_split=i) \n",
    "    DTC = DTC.fit(X_train,y_train)\n",
    "    print(\"min_samples_split = \",i )\n",
    "    print(DTC.score(X_test,y_test)) # min_samples_split =  3 ou 7 ----   0.2000348796651552\n",
    "    print(\"-\"*20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_classifieurs= [\n",
    "    [\"Perceptron\", Perceptron(eta0=0.1, random_state=0)],\n",
    "    [\"Logistic Regression\", LogisticRegression()],\n",
    "    [\"Decision Tree\", DecisionTreeClassifier(max_depth=15,min_samples_split=3)],\n",
    "    [\"linear_svc\", LinearSVC()],\n",
    "    [\"naive_bayes\",MultinomialNB()]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectoriser : Les paramètres lowercase, stop_words, max_features, analyzer = \"char\" ou \"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords : False, Minuscules : False\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.4402\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.4611\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.1907\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.5023\n",
      "  Nouvelle expérience\n",
      "  naive_bayes classifier : 0.3835\n",
      "Stopwords : False, Minuscules : True\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.4474\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.4645\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.1953\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.5027\n",
      "  Nouvelle expérience\n",
      "  naive_bayes classifier : 0.3848\n",
      "Stopwords : True, Minuscules : False\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.4603\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.4870\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.1683\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.5233\n",
      "  Nouvelle expérience\n",
      "  naive_bayes classifier : 0.4262\n",
      "Stopwords : True, Minuscules : True\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.4575\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.4883\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.1547\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.5202\n",
      "  Nouvelle expérience\n",
      "  naive_bayes classifier : 0.4285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import _stop_words\n",
    "min_N, max_N = 1, 2\n",
    "\n",
    "for enlever_stopwords in [False,True]:\n",
    "  liste_stopwords = None\n",
    "  if enlever_stopwords==True:\n",
    "    liste_stopwords = _stop_words.ENGLISH_STOP_WORDS\n",
    "    \n",
    "  for en_minuscules in [False, True]:\n",
    "    print(f\"Stopwords : {enlever_stopwords}, Minuscules : {en_minuscules}\")\n",
    "    for max_F in [40000]:\n",
    "        V = TfidfVectorizer(lowercase = en_minuscules, stop_words =  liste_stopwords, max_features = max_F,ngram_range=(min_N, max_N),)\n",
    "        X = V.fit_transform(liste_brown)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "        for nom, algo in liste_classifieurs:\n",
    "            clf = algo.fit(X_train, y_train)\n",
    "            expe = str([nom, min_N, max_N, enlever_stopwords, en_minuscules, max_F])\n",
    "            if expe in dic_expes:\n",
    "                score = dic_expes[expe]\n",
    "                #expe.append()\n",
    "                print(\"  Déjà vu :\",  expe, \"%.4f\"%score)    \n",
    "                \n",
    "            else:\n",
    "\n",
    "                print(\"  Nouvelle expérience\")\n",
    "                score = clf.score(X_test, y_test)\n",
    "                print('  %s classifier : %.4f'%(nom, score))\n",
    "                \n",
    "                dic_expes[expe] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords False, Minuscules : False\n",
      "  Déjà vu : ['Perceptron', 1, 3, False, False, 30000] 0.42849668643181027\n",
      "  Déjà vu : ['Logistic Regression', 1, 3, False, False, 30000] 0.4188466457388676\n",
      "  Déjà vu : ['Decision Tree', 1, 3, False, False, 30000] 0.45273805371468434\n",
      "  Déjà vu : ['linear_svc', 1, 3, False, False, 30000] 0.19608185094756422\n",
      "  Déjà vu : ['naive_bayes', 1, 3, False, False, 30000] 0.4802929891873038\n",
      "Stopwords False, Minuscules : True\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.3870\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.4226\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.4574\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.1948\n",
      "  Nouvelle expérience\n",
      "  naive_bayes classifier : 0.4835\n",
      "Stopwords True, Minuscules : False\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.3901\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.4532\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.4859\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.1666\n",
      "  Nouvelle expérience\n",
      "  naive_bayes classifier : 0.5173\n",
      "Stopwords True, Minuscules : True\n",
      "  Nouvelle expérience\n",
      "  Perceptron classifier : 0.4342\n",
      "  Nouvelle expérience\n",
      "  Logistic Regression classifier : 0.4556\n",
      "  Nouvelle expérience\n",
      "  Decision Tree classifier : 0.4895\n",
      "  Nouvelle expérience\n",
      "  linear_svc classifier : 0.1552\n",
      "  Nouvelle expérience\n",
      "  naive_bayes classifier : 0.5163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import _stop_words\n",
    "\n",
    "min_N, max_N = 1, 3\n",
    "\n",
    "for enlever_stopwords in [False, True]:\n",
    "  liste_stopwords = None\n",
    "  if enlever_stopwords==True:\n",
    "    liste_stopwords = _stop_words.ENGLISH_STOP_WORDS\n",
    "    \n",
    "  for en_minuscules in [False, True]:\n",
    "    print(f\"Stopwords {enlever_stopwords}, Minuscules : {en_minuscules}\")\n",
    "    for max_F in [30000]:\n",
    "        V = TfidfVectorizer(lowercase = en_minuscules, stop_words =  liste_stopwords, max_features = max_F,ngram_range=(min_N, max_N), )\n",
    "        X = V.fit_transform(liste_brown)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "        for nom, algo in liste_classifieurs:\n",
    "            clf = algo.fit(X_train, y_train)\n",
    "            expe = str([nom, min_N, max_N, enlever_stopwords, en_minuscules, max_F])\n",
    "            if expe in dic_expes:\n",
    "                print(\"  Déjà vu :\",  expe, score)\n",
    "                score = dic_expes[expe]\n",
    "            else:\n",
    "                print(\"  Nouvelle expérience\")\n",
    "                print('  %s classifier : %.4f'%(nom, score))\n",
    "                score = clf.score(X_test, y_test)\n",
    "                dic_expes[expe] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords : False, Minuscules : True\n",
      "  Déjà vu : ['Perceptron', 1, 3, False, True, 30000] 0.4226\n",
      "  Déjà vu : ['Logistic Regression', 1, 3, False, True, 30000] 0.4574\n",
      "  Déjà vu : ['Decision Tree', 1, 3, False, True, 30000] 0.1948\n",
      "  Déjà vu : ['linear_svc', 1, 3, False, True, 30000] 0.4835\n",
      "  Déjà vu : ['naive_bayes', 1, 3, False, True, 30000] 0.3901\n"
     ]
    }
   ],
   "source": [
    "min_N, max_N = 1,3 \n",
    "enlever_stopwords,en_minuscules = False,True\n",
    "\n",
    "print(f\"Stopwords : False, Minuscules : True\")\n",
    "max_F = 30000\n",
    "V = TfidfVectorizer(lowercase = True, stop_words = None, max_features = max_F, ngram_range=(min_N, max_N), analyzer = \"word\")\n",
    "X = V.fit_transform(liste_brown)\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "for nom, algo in liste_classifieurs:\n",
    "    clf = algo.fit(X_train, y_train)\n",
    "    expe = str([nom, min_N, max_N, enlever_stopwords, en_minuscules, max_F])\n",
    "    \n",
    "    if expe in dic_expes:\n",
    "        score = dic_expes[expe]\n",
    "            #expe.append()\n",
    "        print(\"  Déjà vu :\",  expe, \"%.4f\"%score)    \n",
    "    else:\n",
    "        print(\"  Nouvelle expérience\")\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print('  %s classifier : %.4f'%(nom, score))\n",
    "        dic_expes[expe] = score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Expériences stockées dans dic_expes_brown.json\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "w = open(chemin_expes, \"w\")\n",
    "w.write(json.dumps(dic_expes))\n",
    "w.close()\n",
    "print(\"-\"*20)\n",
    "print(f\"Expériences stockées dans {chemin_expes}\")\n",
    "print(\"-\"*20)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f305f83ddee5f6083fe6bf1477dd3712b722d33e0c8e3d1f4b66e3f2a7ae2169"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
