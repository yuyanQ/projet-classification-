{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affiche le chemin absolu vers le dossier courant/Users/qianyuyan/Desktop/Projet methodo/brown\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "print(\"Affiche le chemin absolu vers le dossier courant\"+os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import brown\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "                 #\"MNB\":MultinomialNB(),\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # the return value will be an iterable object of type TextFileReader:\n",
    "chunks = pd.read_csv(\"archive/brown.csv\",delimiter=\",\",chunksize=10000) ## 16*chunk\n",
    "df = pd.concat([chunk for chunk in chunks]) \n",
    "liste_brown = df[\"tokenized_text\"].values.tolist()  # ArticleId,Text,Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_classifier = [\n",
    "    [\"Perceptron\", Perceptron(eta0=0.1, random_state=0,max_iter=10000)],\n",
    "    [\"naive_bayes\",MultinomialNB()],\n",
    "    [\"linear_svc\", LinearSVC()],\n",
    "    [\"Tree\",DecisionTreeClassifier()],\n",
    "    [\"Logistic Regression\", LogisticRegression(max_iter=10000)]]\n",
    "\n",
    "liste_Vectorizer = [\n",
    "    #[\"stop\",TfidfVectorizer(stop_words='english')],\n",
    "    [\"max_f:40000\",TfidfVectorizer(max_features = 40000)],\n",
    "    [\"word-ngram:1-2\",TfidfVectorizer(ngram_range = (1,2),analyzer =\"word\")],\n",
    "    [\"word-ngram:1-3\",TfidfVectorizer(ngram_range = (1,3),analyzer =\"word\")],\n",
    "    #[\"char-ngram:1-8\",TfidfVectorizer(ngram_range=(1,8), analyzer=\"char\")]  # dico => liste   0.7s=>0.2s\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_f:40000\n",
      "Bons résultats 16121\n",
      "Erreurs: 24017\n",
      "------------------------------\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.37      0.37      0.37      3278\n",
      " belles_lettres       0.38      0.46      0.42      5057\n",
      "      editorial       0.34      0.20      0.25      2093\n",
      "        fiction       0.34      0.32      0.33      2975\n",
      "     government       0.36      0.57      0.44      2095\n",
      "        hobbies       0.48      0.45      0.46      2939\n",
      "          humor       0.19      0.17      0.18       759\n",
      "        learned       0.56      0.61      0.58      5410\n",
      "           lore       0.37      0.32      0.34      3430\n",
      "        mystery       0.35      0.33      0.34      2693\n",
      "           news       0.48      0.42      0.45      3239\n",
      "       religion       0.35      0.28      0.31      1216\n",
      "        reviews       0.31      0.28      0.29      1225\n",
      "        romance       0.36      0.35      0.36      3057\n",
      "science_fiction       0.25      0.20      0.22       672\n",
      "\n",
      "       accuracy                           0.40     40138\n",
      "      macro avg       0.37      0.36      0.36     40138\n",
      "   weighted avg       0.40      0.40      0.40     40138\n",
      "\n",
      "word-ngram:1-2\n",
      "Bons résultats 15720\n",
      "Erreurs: 24418\n",
      "------------------------------\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.38      0.35      0.36      3278\n",
      " belles_lettres       0.40      0.41      0.41      5057\n",
      "      editorial       0.25      0.26      0.26      2093\n",
      "        fiction       0.41      0.21      0.28      2975\n",
      "     government       0.35      0.58      0.44      2095\n",
      "        hobbies       0.46      0.45      0.46      2939\n",
      "          humor       0.12      0.20      0.15       759\n",
      "        learned       0.52      0.65      0.58      5410\n",
      "           lore       0.37      0.30      0.34      3430\n",
      "        mystery       0.38      0.32      0.35      2693\n",
      "           news       0.46      0.44      0.45      3239\n",
      "       religion       0.30      0.32      0.31      1216\n",
      "        reviews       0.26      0.28      0.27      1225\n",
      "        romance       0.36      0.32      0.34      3057\n",
      "science_fiction       0.24      0.21      0.22       672\n",
      "\n",
      "       accuracy                           0.39     40138\n",
      "      macro avg       0.35      0.35      0.35     40138\n",
      "   weighted avg       0.39      0.39      0.39     40138\n",
      "\n",
      "word-ngram:1-3\n",
      "Bons résultats 15477\n",
      "Erreurs: 24661\n",
      "------------------------------\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.40      0.32      0.36      3278\n",
      " belles_lettres       0.41      0.42      0.41      5057\n",
      "      editorial       0.33      0.20      0.25      2093\n",
      "        fiction       0.43      0.21      0.28      2975\n",
      "     government       0.30      0.57      0.40      2095\n",
      "        hobbies       0.43      0.45      0.44      2939\n",
      "          humor       0.13      0.21      0.16       759\n",
      "        learned       0.45      0.68      0.55      5410\n",
      "           lore       0.37      0.29      0.33      3430\n",
      "        mystery       0.42      0.24      0.31      2693\n",
      "           news       0.43      0.47      0.45      3239\n",
      "       religion       0.31      0.30      0.31      1216\n",
      "        reviews       0.27      0.27      0.27      1225\n",
      "        romance       0.37      0.30      0.33      3057\n",
      "science_fiction       0.23      0.21      0.22       672\n",
      "\n",
      "       accuracy                           0.39     40138\n",
      "      macro avg       0.35      0.34      0.34     40138\n",
      "   weighted avg       0.39      0.39      0.38     40138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classifier\n",
    "for tt in liste_Vectorizer:\n",
    "    V = tt[1]\n",
    "    X = V.fit_transform(liste_brown)\n",
    "    y = df['label']\n",
    "    X_train,X_test, y_train,y_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
    "\n",
    "    ppn = Perceptron(eta0=0.1, random_state=0)\n",
    "    ppn = ppn.fit(X_train, y_train)\n",
    "    y_pred = ppn.predict(X_test)\n",
    "\n",
    "# On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "    print(tt[0])\n",
    "    print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "    print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "    print(\"-\"*30)\n",
    "    report = classification_report(y_test,y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesure de l’efficacité de ces différents classifieurs: exactitude, précision, rappel, F-mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianyuyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "Bons résultats 16999\n",
      "Erreurs: 23139\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.41      0.39      0.40      3278\n",
      " belles_lettres       0.41      0.45      0.43      5057\n",
      "      editorial       0.32      0.25      0.28      2093\n",
      "        fiction       0.34      0.37      0.35      2975\n",
      "     government       0.39      0.57      0.46      2095\n",
      "        hobbies       0.49      0.49      0.49      2939\n",
      "          humor       0.40      0.13      0.20       759\n",
      "        learned       0.60      0.64      0.62      5410\n",
      "           lore       0.39      0.34      0.37      3430\n",
      "        mystery       0.32      0.41      0.36      2693\n",
      "           news       0.50      0.42      0.46      3239\n",
      "       religion       0.41      0.28      0.34      1216\n",
      "        reviews       0.48      0.20      0.28      1225\n",
      "        romance       0.33      0.39      0.36      3057\n",
      "science_fiction       0.39      0.23      0.29       672\n",
      "\n",
      "       accuracy                           0.42     40138\n",
      "      macro avg       0.41      0.37      0.38     40138\n",
      "   weighted avg       0.43      0.42      0.42     40138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classifier\n",
    "for tt in liste_Vectorizer:\n",
    "    V = tt[1]\n",
    "    X = V.fit_transform(liste_brown)\n",
    "    y = df['label']\n",
    "    X_train,X_test, y_train,y_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
    "\n",
    "    ppn = MLPClassifier()\n",
    "    ppn = ppn.fit(X_train, y_train)\n",
    "    y_pred = ppn.predict(X_test)\n",
    "\n",
    "# On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "    print(tt[0])\n",
    "    print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "    print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "\n",
    "    report = classification_report(y_test,y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "Bons résultats 13637\n",
      "Erreurs: 26501\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.52      0.31      0.39      3278\n",
      " belles_lettres       0.23      0.71      0.35      5057\n",
      "      editorial       0.87      0.02      0.04      2093\n",
      "        fiction       0.56      0.18      0.28      2975\n",
      "     government       0.91      0.13      0.23      2095\n",
      "        hobbies       0.79      0.16      0.27      2939\n",
      "          humor       0.00      0.00      0.00       759\n",
      "        learned       0.31      0.86      0.46      5410\n",
      "           lore       0.58      0.13      0.21      3430\n",
      "        mystery       0.60      0.20      0.30      2693\n",
      "           news       0.61      0.32      0.42      3239\n",
      "       religion       1.00      0.00      0.01      1216\n",
      "        reviews       0.00      0.00      0.00      1225\n",
      "        romance       0.39      0.33      0.36      3057\n",
      "science_fiction       0.00      0.00      0.00       672\n",
      "\n",
      "       accuracy                           0.34     40138\n",
      "      macro avg       0.49      0.22      0.22     40138\n",
      "   weighted avg       0.51      0.34      0.29     40138\n",
      "\n",
      "max_f:20000\n",
      "Bons résultats 12965\n",
      "Erreurs: 27173\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.52      0.29      0.37      3278\n",
      " belles_lettres       0.21      0.79      0.33      5057\n",
      "      editorial       0.82      0.01      0.03      2093\n",
      "        fiction       0.59      0.15      0.24      2975\n",
      "     government       0.96      0.07      0.14      2095\n",
      "        hobbies       0.84      0.14      0.24      2939\n",
      "          humor       0.00      0.00      0.00       759\n",
      "        learned       0.35      0.82      0.49      5410\n",
      "           lore       0.62      0.08      0.14      3430\n",
      "        mystery       0.68      0.15      0.25      2693\n",
      "           news       0.68      0.26      0.37      3239\n",
      "       religion       1.00      0.00      0.00      1216\n",
      "        reviews       0.00      0.00      0.00      1225\n",
      "        romance       0.39      0.34      0.37      3057\n",
      "science_fiction       0.00      0.00      0.00       672\n",
      "\n",
      "       accuracy                           0.32     40138\n",
      "      macro avg       0.51      0.21      0.20     40138\n",
      "   weighted avg       0.53      0.32      0.27     40138\n",
      "\n",
      "word-ngram:1-3\n",
      "Bons résultats 9031\n",
      "Erreurs: 31107\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.58      0.05      0.09      3278\n",
      " belles_lettres       0.17      0.70      0.27      5057\n",
      "      editorial       1.00      0.01      0.03      2093\n",
      "        fiction       0.59      0.02      0.04      2975\n",
      "     government       1.00      0.02      0.03      2095\n",
      "        hobbies       0.99      0.02      0.05      2939\n",
      "          humor       0.00      0.00      0.00       759\n",
      "        learned       0.26      0.88      0.40      5410\n",
      "           lore       0.67      0.00      0.01      3430\n",
      "        mystery       0.54      0.01      0.03      2693\n",
      "           news       0.84      0.03      0.05      3239\n",
      "       religion       1.00      0.00      0.00      1216\n",
      "        reviews       1.00      0.00      0.00      1225\n",
      "        romance       0.40      0.09      0.15      3057\n",
      "science_fiction       0.00      0.00      0.00       672\n",
      "\n",
      "       accuracy                           0.22     40138\n",
      "      macro avg       0.60      0.12      0.08     40138\n",
      "   weighted avg       0.58      0.22      0.12     40138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classifier \"naive_bayes\",MultinomialNB()\n",
    "for tt in liste_Vectorizer:\n",
    "    V = tt[1]\n",
    "    X = V.fit_transform(liste_brown)\n",
    "    y = df['label']\n",
    "    X_train,X_test, y_train,y_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
    "\n",
    "    mb = MultinomialNB()\n",
    "    mb = mb.fit(X_train, y_train)\n",
    "    y_pred = mb.predict(X_test)\n",
    "\n",
    "# On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "    print(tt[0])\n",
    "    print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "    print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "\n",
    "    report = classification_report(y_test,y_pred,zero_division=0)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "Bons résultats 18035\n",
      "Erreurs: 22103\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.41      0.42      0.41      3278\n",
      " belles_lettres       0.42      0.49      0.46      5057\n",
      "      editorial       0.37      0.25      0.30      2093\n",
      "        fiction       0.38      0.37      0.37      2975\n",
      "     government       0.54      0.51      0.52      2095\n",
      "        hobbies       0.51      0.50      0.51      2939\n",
      "          humor       0.48      0.18      0.26       759\n",
      "        learned       0.53      0.70      0.61      5410\n",
      "           lore       0.42      0.38      0.40      3430\n",
      "        mystery       0.40      0.40      0.40      2693\n",
      "           news       0.50      0.48      0.49      3239\n",
      "       religion       0.49      0.33      0.39      1216\n",
      "        reviews       0.47      0.27      0.34      1225\n",
      "        romance       0.36      0.42      0.38      3057\n",
      "science_fiction       0.47      0.26      0.33       672\n",
      "\n",
      "       accuracy                           0.45     40138\n",
      "      macro avg       0.45      0.40      0.41     40138\n",
      "   weighted avg       0.45      0.45      0.44     40138\n",
      "\n",
      "max_f:20000\n",
      "Bons résultats 18482\n",
      "Erreurs: 21656\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.42      0.44      0.43      3278\n",
      " belles_lettres       0.42      0.51      0.46      5057\n",
      "      editorial       0.37      0.26      0.31      2093\n",
      "        fiction       0.37      0.37      0.37      2975\n",
      "     government       0.56      0.53      0.54      2095\n",
      "        hobbies       0.53      0.53      0.53      2939\n",
      "          humor       0.50      0.17      0.25       759\n",
      "        learned       0.56      0.71      0.63      5410\n",
      "           lore       0.43      0.38      0.40      3430\n",
      "        mystery       0.41      0.41      0.41      2693\n",
      "           news       0.51      0.49      0.50      3239\n",
      "       religion       0.48      0.31      0.38      1216\n",
      "        reviews       0.45      0.26      0.33      1225\n",
      "        romance       0.38      0.43      0.41      3057\n",
      "science_fiction       0.51      0.25      0.33       672\n",
      "\n",
      "       accuracy                           0.46     40138\n",
      "      macro avg       0.46      0.40      0.42     40138\n",
      "   weighted avg       0.46      0.46      0.45     40138\n",
      "\n",
      "word-ngram:1-3\n",
      "Bons résultats 17525\n",
      "Erreurs: 22613\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.41      0.42      0.41      3278\n",
      " belles_lettres       0.37      0.56      0.45      5057\n",
      "      editorial       0.51      0.16      0.24      2093\n",
      "        fiction       0.37      0.32      0.34      2975\n",
      "     government       0.63      0.49      0.55      2095\n",
      "        hobbies       0.55      0.46      0.50      2939\n",
      "          humor       0.70      0.06      0.11       759\n",
      "        learned       0.46      0.79      0.58      5410\n",
      "           lore       0.44      0.27      0.33      3430\n",
      "        mystery       0.39      0.37      0.38      2693\n",
      "           news       0.53      0.51      0.52      3239\n",
      "       religion       0.61      0.19      0.29      1216\n",
      "        reviews       0.61      0.11      0.19      1225\n",
      "        romance       0.35      0.43      0.39      3057\n",
      "science_fiction       0.55      0.11      0.19       672\n",
      "\n",
      "       accuracy                           0.44     40138\n",
      "      macro avg       0.50      0.35      0.36     40138\n",
      "   weighted avg       0.46      0.44      0.42     40138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classifier \"linear_svc\", LinearSVC()\n",
    "for tt in liste_Vectorizer:\n",
    "    V = tt[1]\n",
    "    X = V.fit_transform(liste_brown)\n",
    "    y = df['label']\n",
    "    X_train,X_test, y_train,y_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
    "\n",
    "    LSVC =  LinearSVC()\n",
    "    LSVC = LSVC.fit(X_train, y_train)\n",
    "    y_pred = LSVC.predict(X_test)\n",
    "\n",
    "# On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "    print(tt[0])\n",
    "    print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "    print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "\n",
    "    report = classification_report(y_test,y_pred,zero_division=0)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "Bons résultats 10577\n",
      "Erreurs: 29561\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.24      0.24      0.24      3278\n",
      " belles_lettres       0.28      0.29      0.28      5057\n",
      "      editorial       0.17      0.14      0.15      2093\n",
      "        fiction       0.24      0.18      0.21      2975\n",
      "     government       0.15      0.41      0.22      2095\n",
      "        hobbies       0.34      0.26      0.29      2939\n",
      "          humor       0.14      0.09      0.11       759\n",
      "        learned       0.43      0.44      0.44      5410\n",
      "           lore       0.25      0.20      0.22      3430\n",
      "        mystery       0.24      0.23      0.23      2693\n",
      "           news       0.30      0.28      0.29      3239\n",
      "       religion       0.28      0.17      0.21      1216\n",
      "        reviews       0.22      0.15      0.18      1225\n",
      "        romance       0.22      0.24      0.23      3057\n",
      "science_fiction       0.34      0.14      0.19       672\n",
      "\n",
      "       accuracy                           0.26     40138\n",
      "      macro avg       0.26      0.23      0.23     40138\n",
      "   weighted avg       0.27      0.26      0.26     40138\n",
      "\n",
      "max_f:20000\n",
      "Bons résultats 7351\n",
      "Erreurs: 32787\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.18      0.17      0.18      3278\n",
      " belles_lettres       0.18      0.19      0.18      5057\n",
      "      editorial       0.10      0.09      0.09      2093\n",
      "        fiction       0.16      0.15      0.16      2975\n",
      "     government       0.18      0.29      0.22      2095\n",
      "        hobbies       0.22      0.20      0.21      2939\n",
      "          humor       0.05      0.03      0.04       759\n",
      "        learned       0.30      0.34      0.32      5410\n",
      "           lore       0.12      0.12      0.12      3430\n",
      "        mystery       0.15      0.16      0.16      2693\n",
      "           news       0.19      0.17      0.18      3239\n",
      "       religion       0.13      0.09      0.10      1216\n",
      "        reviews       0.06      0.05      0.05      1225\n",
      "        romance       0.17      0.18      0.17      3057\n",
      "science_fiction       0.07      0.05      0.06       672\n",
      "\n",
      "       accuracy                           0.18     40138\n",
      "      macro avg       0.15      0.15      0.15     40138\n",
      "   weighted avg       0.18      0.18      0.18     40138\n",
      "\n",
      "word-ngram:1-3\n",
      "Bons résultats 6944\n",
      "Erreurs: 33194\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.18      0.17      0.17      3278\n",
      " belles_lettres       0.17      0.19      0.18      5057\n",
      "      editorial       0.09      0.08      0.08      2093\n",
      "        fiction       0.15      0.15      0.15      2975\n",
      "     government       0.18      0.28      0.22      2095\n",
      "        hobbies       0.19      0.17      0.18      2939\n",
      "          humor       0.02      0.01      0.01       759\n",
      "        learned       0.29      0.31      0.30      5410\n",
      "           lore       0.11      0.11      0.11      3430\n",
      "        mystery       0.13      0.13      0.13      2693\n",
      "           news       0.18      0.17      0.17      3239\n",
      "       religion       0.14      0.09      0.11      1216\n",
      "        reviews       0.06      0.05      0.06      1225\n",
      "        romance       0.17      0.19      0.18      3057\n",
      "science_fiction       0.08      0.05      0.06       672\n",
      "\n",
      "       accuracy                           0.17     40138\n",
      "      macro avg       0.14      0.14      0.14     40138\n",
      "   weighted avg       0.17      0.17      0.17     40138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\"Tree\",DecisionTreeClassifier()\n",
    "for tt in liste_Vectorizer:\n",
    "    V = tt[1]\n",
    "    X = V.fit_transform(liste_brown)\n",
    "    y = df['label']\n",
    "    X_train,X_test, y_train,y_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
    "\n",
    "    Tree =  DecisionTreeClassifier()\n",
    "    Tree = Tree.fit(X_train, y_train)\n",
    "    y_pred = Tree.predict(X_test)\n",
    "\n",
    "# On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "    print(tt[0])\n",
    "    print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "    print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "\n",
    "    report = classification_report(y_test,y_pred,zero_division=0)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "Bons résultats 16494\n",
      "Erreurs: 23644\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.42      0.39      0.40      3278\n",
      " belles_lettres       0.32      0.62      0.42      5057\n",
      "      editorial       0.52      0.11      0.18      2093\n",
      "        fiction       0.41      0.30      0.35      2975\n",
      "     government       0.65      0.38      0.48      2095\n",
      "        hobbies       0.57      0.39      0.47      2939\n",
      "          humor       1.00      0.01      0.02       759\n",
      "        learned       0.41      0.78      0.54      5410\n",
      "           lore       0.42      0.30      0.35      3430\n",
      "        mystery       0.44      0.32      0.37      2693\n",
      "           news       0.51      0.45      0.48      3239\n",
      "       religion       0.65      0.12      0.20      1216\n",
      "        reviews       0.60      0.05      0.08      1225\n",
      "        romance       0.37      0.40      0.38      3057\n",
      "science_fiction       1.00      0.03      0.06       672\n",
      "\n",
      "       accuracy                           0.41     40138\n",
      "      macro avg       0.55      0.31      0.32     40138\n",
      "   weighted avg       0.47      0.41      0.38     40138\n",
      "\n",
      "max_f:20000\n",
      "Bons résultats 16669\n",
      "Erreurs: 23469\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.40      0.42      0.41      3278\n",
      " belles_lettres       0.34      0.58      0.43      5057\n",
      "      editorial       0.46      0.12      0.19      2093\n",
      "        fiction       0.35      0.31      0.33      2975\n",
      "     government       0.67      0.39      0.49      2095\n",
      "        hobbies       0.52      0.44      0.48      2939\n",
      "          humor       1.00      0.01      0.02       759\n",
      "        learned       0.44      0.78      0.57      5410\n",
      "           lore       0.41      0.27      0.32      3430\n",
      "        mystery       0.41      0.33      0.36      2693\n",
      "           news       0.49      0.48      0.48      3239\n",
      "       religion       0.66      0.10      0.17      1216\n",
      "        reviews       0.54      0.05      0.09      1225\n",
      "        romance       0.35      0.43      0.39      3057\n",
      "science_fiction       0.88      0.02      0.04       672\n",
      "\n",
      "       accuracy                           0.42     40138\n",
      "      macro avg       0.53      0.32      0.32     40138\n",
      "   weighted avg       0.46      0.42      0.39     40138\n",
      "\n",
      "word-ngram:1-3\n",
      "Bons résultats 12724\n",
      "Erreurs: 27414\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      adventure       0.37      0.31      0.34      3278\n",
      " belles_lettres       0.25      0.58      0.35      5057\n",
      "      editorial       0.88      0.02      0.04      2093\n",
      "        fiction       0.36      0.19      0.25      2975\n",
      "     government       0.90      0.14      0.24      2095\n",
      "        hobbies       0.61      0.18      0.28      2939\n",
      "          humor       0.00      0.00      0.00       759\n",
      "        learned       0.29      0.85      0.43      5410\n",
      "           lore       0.48      0.05      0.09      3430\n",
      "        mystery       0.41      0.17      0.24      2693\n",
      "           news       0.56      0.28      0.37      3239\n",
      "       religion       1.00      0.02      0.05      1216\n",
      "        reviews       0.50      0.00      0.00      1225\n",
      "        romance       0.31      0.39      0.34      3057\n",
      "science_fiction       0.00      0.00      0.00       672\n",
      "\n",
      "       accuracy                           0.32     40138\n",
      "      macro avg       0.46      0.21      0.20     40138\n",
      "   weighted avg       0.45      0.32      0.26     40138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "for tt in liste_Vectorizer:\n",
    "    V = tt[1]\n",
    "    X = V.fit_transform(liste_brown)\n",
    "    y = df['label']\n",
    "    X_train,X_test, y_train,y_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
    "\n",
    "    LR =  LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    LR = LR.fit(X_train, y_train)\n",
    "    y_pred = LR.predict(X_test)\n",
    "\n",
    "# On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "    print(tt[0])\n",
    "    print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "    print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "\n",
    "    report = classification_report(y_test,y_pred,zero_division=0)\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f305f83ddee5f6083fe6bf1477dd3712b722d33e0c8e3d1f4b66e3f2a7ae2169"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
